{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4005bb8",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0954f6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import logging\n",
    "from datetime import datetime\n",
    "import requests\n",
    "from io import StringIO\n",
    "from scipy.stats import beta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35e1ccc",
   "metadata": {},
   "source": [
    "# Global Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0419c7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Back-test date range\n",
    "BACKTEST_START     = '2021-01-01' \n",
    "BACKTEST_END       = '2025-11-07' \n",
    "# BACKTEST_START     = '2011-06-01' \n",
    "# BACKTEST_END       = '2025-06-01' \n",
    "\n",
    "# Rolling window length (in months)\n",
    "INVESTMENT_WINDOW  = 12\n",
    "\n",
    "# Step frequency for window start-dates: 'Daily', 'Weekly' or 'Monthly'\n",
    "PURCHASE_FREQ      = 'Daily'\n",
    "\n",
    "# Minimum per-period weight (to avoid zero allocations)\n",
    "MIN_WEIGHT         = 1e-5\n",
    "\n",
    "PURCHASE_FREQ_TO_OFFSET = {\n",
    "    'Daily':   '1D',\n",
    "    'Weekly':  '7D',\n",
    "    'Monthly': '1M',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b1e616f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "    format='%(asctime)s %(levelname)-8s %(message)s',\n",
    "    level=logging.INFO,\n",
    "    datefmt='%Y-%m-%d %H:%M:%S'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf4ed3b",
   "metadata": {},
   "source": [
    "# Download BTC Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6d196e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from coinmetrics.api_client import CoinMetricsClient\n",
    "except ImportError:\n",
    "    raise ImportError(\"coinmetrics.api_client module is required. Install it via pip:\\n\\n    pip install coinmetrics-api-client\")\n",
    "\n",
    "def extract_btc_data_to_csv(local_path='btc_data.csv'):\n",
    "    # Coin Metrics BTC CSV (raw GitHub URL)\n",
    "    url = \"https://raw.githubusercontent.com/coinmetrics/data/master/csv/btc.csv\"\n",
    "    \n",
    "    # Download the content\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()  # raises an error for bad responses\n",
    "    \n",
    "    # Parse CSV content\n",
    "    btc_df = pd.read_csv(StringIO(response.text))\n",
    "\n",
    "    btc_df['time'] = pd.to_datetime(btc_df['time']).dt.normalize()\n",
    "    btc_df['time'] = btc_df['time'].dt.tz_localize(None)\n",
    "    btc_df.set_index('time', inplace=True)\n",
    "\n",
    "    btc_df.to_csv(local_path)\n",
    "    \n",
    "    # Show the df\n",
    "    btc_df\n",
    "\n",
    "btc_df = extract_btc_data_to_csv(\"btc_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa96c44",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "954a2406",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    df = pd.read_csv(\"btc_data.csv\", index_col=0, parse_dates=True)\n",
    "    df = df.loc[~df.index.duplicated(keep='last')]\n",
    "    df = df.sort_index()\n",
    "    return df\n",
    "\n",
    "def validate_price_data(df):\n",
    "    if df.empty or 'PriceUSD' not in df.columns:\n",
    "        raise ValueError(\"Invalid BTC price data.\")\n",
    "    if not isinstance(df.index, pd.DatetimeIndex):\n",
    "        raise ValueError(\"Index must be datetime.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23dc2da1",
   "metadata": {},
   "source": [
    "# Strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2761bf04",
   "metadata": {},
   "source": [
    "## Hyper Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "be239c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "_FULL_FEATURES = None\n",
    "\n",
    "MIN_W = 1e-5\n",
    "WINS = [30, 90, 180, 365, 1461]\n",
    "FEATS = [f\"z{w}\" for w in WINS]\n",
    "PROTOS = [(0.5, 5.0), (1.0, 1.0), (5.0, 0.5)]\n",
    "\n",
    "# Optimized theta parameters from the final model run\n",
    "THETA = np.array([1.6741, 0.0805, 0.4075, -0.0023,\n",
    " 1.2621, 2.1404, -0.7984, -0.0140,\n",
    " -0.1359, 0.0563, -0.5971, -1.0053,\n",
    " -0.8718, -0.0651, -0.2813, -0.0571,\n",
    " -0.6538, -1.1288, 0.0000, 0.0000,\n",
    " 0.3622, 1.9998, 5.0000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e574063f",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ba738b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Converts a vector of scores into a probability distribution.\"\"\"\n",
    "    ex = np.exp(x - x.max())\n",
    "    return ex / ex.sum()\n",
    "\n",
    "def allocate_sequential(raw: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Strict left-to-right 'drain' allocator.\"\"\"\n",
    "    n = len(raw)\n",
    "    floor = n * MIN_W\n",
    "    rem_budget, rem_raw = 1 - floor, raw.sum()\n",
    "    w = np.empty_like(raw)\n",
    "    for i, x in enumerate(raw):\n",
    "        share = 0 if rem_raw == 0 else (x / rem_raw) * rem_budget\n",
    "        w[i] = MIN_W + share\n",
    "        rem_budget -= share\n",
    "        rem_raw -= x\n",
    "    return w / w.sum()\n",
    "\n",
    "def beta_mix_pdf(n: int, mix: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Generates a smooth baseline curve from a mixture of Beta distributions.\"\"\"\n",
    "    t = np.linspace(0.5 / n, 1 - 0.5 / n, n)\n",
    "    return (mix[0] * beta.pdf(t, *PROTOS[0]) +\n",
    "            mix[1] * beta.pdf(t, *PROTOS[1]) +\n",
    "            mix[2] * beta.pdf(t, *PROTOS[2])) / n\n",
    "\n",
    "def zscore(s: pd.Series, win: int) -> pd.Series:\n",
    "    \"\"\"Calculates the rolling z-score for a given series and window.\"\"\"\n",
    "    m = s.rolling(win, win // 2).mean()\n",
    "    sd = s.rolling(win, win // 2).std()\n",
    "    return ((s - m) / sd).fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b5d7fd",
   "metadata": {},
   "source": [
    "## Main Strategy Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "dea94e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Calculates features on the full historical data ONCE and returns the\n",
    "    relevant slice. This robustly handles calls from different boilerplate\n",
    "    functions and avoids boundary errors that cause leakage.\n",
    "    \"\"\"\n",
    "    global _FULL_FEATURES\n",
    "\n",
    "    # Only compute the full feature set if it hasn't been done yet.\n",
    "    if _FULL_FEATURES is None:\n",
    "        try:\n",
    "            # Assumes 'btc_data.csv' is in the same directory.\n",
    "            full_price_df = pd.read_csv(\"btc_data.csv\", index_col=0, parse_dates=True)\n",
    "        except FileNotFoundError:\n",
    "            raise FileNotFoundError(\"btc_data.csv not found. Please ensure it's in the correct directory.\")\n",
    "        \n",
    "        # Select only the PriceUSD column before doing anything else.\n",
    "        full_price_df = full_price_df[['PriceUSD']]\n",
    "        \n",
    "        # We need history from before the backtest start date for rolling windows.\n",
    "        full_price_df = full_price_df.loc[\"2020-02-18\":]\n",
    "        # full_price_df = full_price_df.loc[\"2010-07-18\":] \n",
    "\n",
    "        log_prices = np.log(full_price_df['PriceUSD'])\n",
    "        \n",
    "        z_all = pd.DataFrame({f\"z{w}\": zscore(log_prices, w).clip(-4, 4) for w in WINS}, index=log_prices.index)\n",
    "        \n",
    "        # The strategy uses lagged features to avoid look-ahead bias.\n",
    "        z_lag = z_all.shift(1).fillna(0)\n",
    "        \n",
    "        _FULL_FEATURES = full_price_df.join(z_lag)\n",
    "\n",
    "    # Return the portion of the pre-computed features that matches the input index.\n",
    "    return _FULL_FEATURES.reindex(df.index).fillna(0)\n",
    "\n",
    "def compute_weights(df_window: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Given a slice of data, computes portfolio weights that sum to 1.\n",
    "    This function first calls construct_features to ensure the necessary\n",
    "    feature columns are present.\n",
    "    \"\"\"\n",
    "    if df_window.empty:\n",
    "        return pd.Series(dtype=float)\n",
    "\n",
    "    feat_slice = construct_features(df_window)\n",
    "\n",
    "    alpha, beta_v = THETA[:18].reshape(3, 6), THETA[18:]\n",
    "    \n",
    "    # Use features from the first day to set the annual strategy\n",
    "    first_day_feats = feat_slice[FEATS].iloc[0].values\n",
    "    mix = softmax(alpha @ np.r_[1, first_day_feats])\n",
    "    \n",
    "    # Calculate the components of the allocation formula\n",
    "    n_days = len(feat_slice)\n",
    "    base_alloc = beta_mix_pdf(n_days, mix)\n",
    "    dynamic_signal = np.exp(-(feat_slice[FEATS].values @ beta_v))\n",
    "    \n",
    "    # Combine signals and compute final weights\n",
    "    raw_weights = base_alloc * dynamic_signal\n",
    "    final_weights = allocate_sequential(raw_weights)\n",
    "    \n",
    "    return pd.Series(final_weights, index=feat_slice.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f83f170",
   "metadata": {},
   "source": [
    "# Run Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3096e9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _make_window_label(window_start: pd.Timestamp, window_end: pd.Timestamp) -> str:\n",
    "    \"\"\"\n",
    "    Format \"YYYY-MM-DD → YYYY-MM-DD\" for a rolling window.\n",
    "    \"\"\"\n",
    "    start_str = pd.to_datetime(window_start).strftime(\"%Y-%m-%d\")\n",
    "    end_str   = pd.to_datetime(window_end).strftime(\"%Y-%m-%d\")\n",
    "    return f\"{start_str} → {end_str}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7c7e18e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cycle_spd(\n",
    "    dataframe: pd.DataFrame,\n",
    "    strategy_function\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Compute sats‐per‐dollar (SPD) stats over rolling windows.\n",
    "\n",
    "    - Uses full‐history features (no look‐ahead).\n",
    "    - Window length = INVESTMENT_WINDOW months.\n",
    "    - Step every PURCHASE_FREQ.\n",
    "    - Returns a DataFrame indexed by window label, with:\n",
    "        min_sats_per_dollar, max_sats_per_dollar,\n",
    "        uniform_sats_per_dollar, dynamic_sats_per_dollar,\n",
    "        uniform_percentile, dynamic_percentile, excess_percentile.\n",
    "    \"\"\"\n",
    "    # 1) Precompute full-history features & restrict to backtest\n",
    "    full_feat = construct_features(dataframe).loc[BACKTEST_START:BACKTEST_END]\n",
    "\n",
    "    # 2) Window parameters\n",
    "    window_offset  = pd.DateOffset(months=INVESTMENT_WINDOW)\n",
    "    step_freq      = PURCHASE_FREQ_TO_OFFSET[PURCHASE_FREQ]\n",
    "\n",
    "    results = []\n",
    "    for window_start in pd.date_range(\n",
    "        start=pd.to_datetime(BACKTEST_START),\n",
    "        end=pd.to_datetime(BACKTEST_END) - window_offset,\n",
    "        freq=step_freq\n",
    "    ):\n",
    "        window_end  = window_start + window_offset\n",
    "        feat_slice  = full_feat.loc[window_start:window_end]\n",
    "        price_slice = dataframe[\"PriceUSD\"].loc[window_start:window_end]\n",
    "\n",
    "        if price_slice.empty:\n",
    "            continue\n",
    "\n",
    "        label       = _make_window_label(window_start, window_end)\n",
    "        inv_price   = (1.0 / price_slice) * 1e8  # sats per dollar\n",
    "\n",
    "        # Compute weights on this slice\n",
    "        weight_slice = strategy_function(feat_slice)\n",
    "\n",
    "        # Uniform vs. dynamic SPD\n",
    "        uniform_spd = inv_price.mean()\n",
    "        dynamic_spd = (weight_slice * inv_price).sum()\n",
    "\n",
    "        # Min/max for percentile scaling\n",
    "        min_spd = inv_price.min()   # low price → high SPD\n",
    "        max_spd = inv_price.max()   # high price → low SPD\n",
    "        span    = max_spd - min_spd\n",
    "\n",
    "        uniform_pct = (uniform_spd - min_spd) / span * 100\n",
    "        dynamic_pct = (dynamic_spd - min_spd) / span * 100\n",
    "\n",
    "        results.append({\n",
    "            \"window\":                   label,\n",
    "            \"min_sats_per_dollar\":      min_spd,\n",
    "            \"max_sats_per_dollar\":      max_spd,\n",
    "            \"uniform_sats_per_dollar\":  uniform_spd,\n",
    "            \"dynamic_sats_per_dollar\":  dynamic_spd,\n",
    "            \"uniform_percentile\":       uniform_pct,\n",
    "            \"dynamic_percentile\":       dynamic_pct,\n",
    "            \"excess_percentile\":        dynamic_pct - uniform_pct,\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(results).set_index(\"window\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50489854",
   "metadata": {},
   "source": [
    "# Backtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64c7f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backtest_dynamic_dca(\n",
    "    dataframe: pd.DataFrame,\n",
    "    strategy_function,\n",
    "    *,\n",
    "    strategy_label: str = \"strategy\"\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    1) Runs compute_cycle_spd(...)\n",
    "    2) Prints aggregated min/max/mean/median of dynamic SPD\n",
    "    3) Prints aggregated SPD percentiles\n",
    "    4) Computes & prints exponentially-decayed average SPD and percentile\n",
    "    5) Returns the full SPD table.\n",
    "\n",
    "    Exponential decay:\n",
    "      • decay_rate ∈ (0,1): lower → faster decay\n",
    "      • most recent window has highest weight\n",
    "      • weights normalized to sum to 1\n",
    "    \"\"\"\n",
    "    # --- run the rolling-window SPD backtest\n",
    "    spd_table   = compute_cycle_spd(dataframe, strategy_function)\n",
    "    dynamic_spd = spd_table[\"dynamic_sats_per_dollar\"]\n",
    "    dynamic_pct = spd_table[\"dynamic_percentile\"]\n",
    "\n",
    "    # --- print standard aggregated metrics\n",
    "    print(f\"\\nAggregated Metrics for {strategy_label}:\")\n",
    "    print(\"Dynamic Sats-per-Dollar:\")\n",
    "    for stat in (\"min\", \"max\", \"mean\", \"median\"):\n",
    "        val = getattr(dynamic_spd, stat)()\n",
    "        print(f\"  {stat}: {val:.2f}\")\n",
    "\n",
    "    print(\"\\nDynamic SPD Percentiles:\")\n",
    "    for stat in (\"min\", \"max\", \"mean\", \"median\"):\n",
    "        val = getattr(dynamic_pct, stat)()\n",
    "        print(f\"  {stat}: {val:.2f}%\")\n",
    "\n",
    "    # --- exponential decay weighting\n",
    "    decay_rate = 0.9\n",
    "    N = len(dynamic_spd)\n",
    "    # weight for window i (0 = oldest, N-1 = newest)\n",
    "    raw_weights = np.array([decay_rate ** (N - 1 - i) for i in range(N)])\n",
    "    exp_weights = raw_weights / raw_weights.sum()\n",
    "\n",
    "    # --- compute decayed averages\n",
    "    exp_avg_spd = (dynamic_spd.values * exp_weights).sum()\n",
    "    exp_avg_pct = (dynamic_pct.values * exp_weights).sum()\n",
    "\n",
    "    # --- print decayed metrics\n",
    "    print(f\"\\nExponential-Decay Average SPD: {exp_avg_spd:.2f}\")\n",
    "    print(f\"Exponential-Decay Average SPD Percentile: {exp_avg_pct:.2f}%\")\n",
    "\n",
    "    return spd_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3dfdc0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_strategy_submission_ready(\n",
    "    dataframe: pd.DataFrame,\n",
    "    strategy_function\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Sanity-check that `strategy_function`:\n",
    "      1. Uses no future data (forward-leakage test).\n",
    "      2. Produces weights ≥ MIN_WEIGHT.\n",
    "      3. Sums to 1.0 in each rolling window.\n",
    "      4. Outperforms uniform DCA in at least 50% of rolling windows.\n",
    "    \"\"\"\n",
    "    passed = True\n",
    "\n",
    "    # ──────────────────────────────────────────────────────────\n",
    "    # 1) Forward-leakage test\n",
    "    # ──────────────────────────────────────────────────────────\n",
    "    backtest_df  = dataframe.loc[BACKTEST_START:BACKTEST_END]\n",
    "    full_weights = strategy_function(dataframe) \\\n",
    "                       .reindex(backtest_df.index) \\\n",
    "                       .fillna(0.0)\n",
    "\n",
    "    step_dates = max(len(backtest_df) // 50, 1)\n",
    "    probe_dates = backtest_df.index[::step_dates]\n",
    "\n",
    "    for probe in probe_dates:\n",
    "        masked = dataframe.copy()\n",
    "        masked.loc[masked.index > probe, :] = np.nan\n",
    "\n",
    "        masked_wt = strategy_function(masked) \\\n",
    "                        .reindex(full_weights.index) \\\n",
    "                        .fillna(0.0)\n",
    "\n",
    "        if not np.isclose(masked_wt.loc[probe],\n",
    "                          full_weights.loc[probe],\n",
    "                          rtol=1e-9, atol=1e-12):\n",
    "            delta = abs(masked_wt.loc[probe] - full_weights.loc[probe])\n",
    "            print(f\"[{probe.date()}] ❌ Forward-leakage detected (Δ={delta:.2e})\")\n",
    "            passed = False\n",
    "            break\n",
    "\n",
    "    # ──────────────────────────────────────────────────────────\n",
    "    # 2) Weight checks per rolling window\n",
    "    # ──────────────────────────────────────────────────────────\n",
    "    window_offset = pd.DateOffset(months=INVESTMENT_WINDOW)\n",
    "    step_freq     = PURCHASE_FREQ_TO_OFFSET[PURCHASE_FREQ]\n",
    "\n",
    "    for window_start in pd.date_range(\n",
    "        start=pd.to_datetime(BACKTEST_START),\n",
    "        end=pd.to_datetime(BACKTEST_END) - window_offset,\n",
    "        freq=step_freq\n",
    "    ):\n",
    "        window_end = window_start + window_offset\n",
    "        label      = _make_window_label(window_start, window_end)\n",
    "\n",
    "        w_slice = strategy_function(dataframe.loc[window_start:window_end])\n",
    "\n",
    "        if (w_slice <= 0).any():\n",
    "            print(f\"[{label}] ❌ Non-positive weights detected.\")\n",
    "            passed = False\n",
    "\n",
    "        if (w_slice < MIN_WEIGHT).any():\n",
    "            print(f\"[{label}] ❌ Weight below MIN_WEIGHT = {MIN_WEIGHT}.\")\n",
    "            passed = False\n",
    "\n",
    "        total = w_slice.sum()\n",
    "        if not np.isclose(total, 1.0, rtol=1e-5, atol=1e-8):\n",
    "            print(f\"[{label}] ❌ Sum-to-1 check failed: {total:.4f}\")\n",
    "            passed = False\n",
    "\n",
    "    # ──────────────────────────────────────────────────────────\n",
    "    # 3) Performance vs. Uniform DCA (RELAXED)\n",
    "    # ──────────────────────────────────────────────────────────\n",
    "    spd_table = compute_cycle_spd(dataframe, strategy_function)\n",
    "\n",
    "    underperf_records = []\n",
    "    for label, row in spd_table.iterrows():\n",
    "        dp, up = row[\"dynamic_percentile\"], row[\"uniform_percentile\"]\n",
    "        if dp < up:\n",
    "            underperf_records.append({\n",
    "                \"Window\": label,\n",
    "                \"Dynamic Percentile\": dp,\n",
    "                \"Uniform Percentile\": up,\n",
    "                \"Delta\": dp - up\n",
    "            })\n",
    "\n",
    "    total = len(spd_table)\n",
    "    failed = len(underperf_records)\n",
    "    pass_ratio = (total - failed) / total\n",
    "\n",
    "    if underperf_records:\n",
    "        df_underperf = pd.DataFrame(underperf_records)\n",
    "        print(\"\\n⚠️ Windows where strategy underperformed Uniform DCA:\")\n",
    "        display(df_underperf)\n",
    "\n",
    "    print(f\"\\nSummary: Your strategy underperformed uniform DCA in {failed} out of {total} windows \"\n",
    "          f\"({100 * pass_ratio:.2f}% win rate)\")\n",
    "\n",
    "    if pass_ratio >= 0.5:\n",
    "        print(\"✅ Strategy meets performance requirement (≥ 50% win rate vs. uniform DCA).\")\n",
    "    else:\n",
    "        print(\"❌ Strategy failed performance requirement (< 50% win rate vs. uniform DCA).\")\n",
    "        passed = False\n",
    "\n",
    "    # ──────────────────────────────────────────────────────────\n",
    "    # Final verdict\n",
    "    # ──────────────────────────────────────────────────────────\n",
    "    if passed:\n",
    "        print(\"\\n✅ Strategy is ready for submission.\")\n",
    "    else:\n",
    "        print(\"\\n⚠️ Please address the above issues before submitting.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f38f05",
   "metadata": {},
   "source": [
    "# Run main workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7675039f",
   "metadata": {},
   "outputs": [],
   "source": [
    "btc_df = load_data()\n",
    "validate_price_data(btc_df)\n",
    "btc_df = btc_df.loc[BACKTEST_START:BACKTEST_END]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3cbdfbb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Aggregated Metrics for Dynamic DCA:\n",
      "Dynamic Sats-per-Dollar:\n",
      "  min: 1205.97\n",
      "  max: 5985.96\n",
      "  mean: 3762.90\n",
      "  median: 3767.75\n",
      "\n",
      "Dynamic SPD Percentiles:\n",
      "  min: 54.16%\n",
      "  max: 97.38%\n",
      "  mean: 81.52%\n",
      "  median: 84.94%\n",
      "\n",
      "Exponential-Decay Average SPD: 1343.20654\n",
      "Exponential-Decay Average SPD Percentile: 81.75119%\n"
     ]
    }
   ],
   "source": [
    "# Rolling-window SPD backtest:\n",
    "df_spd = backtest_dynamic_dca(\n",
    "    btc_df,\n",
    "    compute_weights,\n",
    "    strategy_label=\"Dynamic DCA\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8d587074",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary: Your strategy underperformed uniform DCA in 0 out of 1407 windows (100.00% win rate)\n",
      "✅ Strategy meets performance requirement (≥ 50% win rate vs. uniform DCA).\n",
      "\n",
      "✅ Strategy is ready for submission.\n"
     ]
    }
   ],
   "source": [
    "# Sanity checks (each window inside):\n",
    "check_strategy_submission_ready(btc_df, compute_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519c9a7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Model Score (50/50 weighting): 91.45%\n"
     ]
    }
   ],
   "source": [
    "win_rate = 100\n",
    "exp_decay_percentile = 81.75\n",
    "\n",
    "score = 0.5 * win_rate + 0.5 * exp_decay_percentile\n",
    "print(f\"Final Model Score (50/50 weighting): {score:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f75dc0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
