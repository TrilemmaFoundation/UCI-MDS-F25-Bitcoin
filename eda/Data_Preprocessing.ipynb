{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28501146",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2a2cad2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from scipy.stats import beta\n",
    "from datetime import datetime\n",
    "import logging\n",
    "import requests\n",
    "from io import StringIO\n",
    "import io\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib.animation import FuncAnimation, PillowWriter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f132550c",
   "metadata": {},
   "source": [
    "# Global Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "68bfc346",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Back-test date range\n",
    "BACKTEST_START     = '2011-06-01' \n",
    "BACKTEST_END       = '2025-06-01' \n",
    "\n",
    "# Rolling window length (in months)\n",
    "INVESTMENT_WINDOW  = 12\n",
    "\n",
    "# Step frequency for window start-dates: 'Daily', 'Weekly' or 'Monthly'\n",
    "PURCHASE_FREQ      = 'Daily'\n",
    "\n",
    "# Minimum per-period weight (to avoid zero allocations)\n",
    "MIN_WEIGHT         = 1e-5\n",
    "\n",
    "PURCHASE_FREQ_TO_OFFSET = {\n",
    "    'Daily':   '1D',\n",
    "    'Weekly':  '7D',\n",
    "    'Monthly': '1M',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ad558dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "    format='%(asctime)s %(levelname)-8s %(message)s',\n",
    "    level=logging.INFO,\n",
    "    datefmt='%Y-%m-%d %H:%M:%S'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e7ae80",
   "metadata": {},
   "source": [
    "# Download BTC Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7cfa6777",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from coinmetrics.api_client import CoinMetricsClient\n",
    "except ImportError:\n",
    "    raise ImportError(\"coinmetrics.api_client module is required. Install it via pip:\\n\\n    pip install coinmetrics-api-client\")\n",
    "\n",
    "def extract_btc_data_to_csv(local_path='data/btc_data.csv'):\n",
    "    # Coin Metrics BTC CSV (raw GitHub URL)\n",
    "    url = \"https://raw.githubusercontent.com/coinmetrics/data/master/csv/btc.csv\"\n",
    "    \n",
    "    # Download the content\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()  # raises an error for bad responses\n",
    "    \n",
    "    # Parse CSV content\n",
    "    btc_df = pd.read_csv(StringIO(response.text))\n",
    "\n",
    "    btc_df['time'] = pd.to_datetime(btc_df['time']).dt.normalize()\n",
    "    btc_df['time'] = btc_df['time'].dt.tz_localize(None)\n",
    "    btc_df.set_index('time', inplace=True)\n",
    "\n",
    "    btc_df.to_csv(local_path)\n",
    "    \n",
    "    # Show the df\n",
    "    btc_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4be90aa",
   "metadata": {},
   "source": [
    "# Load BTC Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "88568ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    df = pd.read_csv(\"data/btc_data.csv\", index_col=0, parse_dates=True)\n",
    "    df = df.loc[~df.index.duplicated(keep='last')]\n",
    "    df = df.sort_index()\n",
    "    return df\n",
    "\n",
    "def validate_price_data(df):\n",
    "    if df.empty or 'PriceUSD' not in df.columns:\n",
    "        raise ValueError(\"Invalid BTC price data.\")\n",
    "    if not isinstance(df.index, pd.DatetimeIndex):\n",
    "        raise ValueError(\"Index must be datetime.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e976d566",
   "metadata": {},
   "source": [
    "# DCA Strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0238b2ca",
   "metadata": {},
   "source": [
    "## Hyper Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ed54491b",
   "metadata": {},
   "outputs": [],
   "source": [
    "_FULL_FEATURES = None\n",
    "\n",
    "MIN_W = 1e-5\n",
    "WINS = [30, 90, 180, 365, 1461]\n",
    "FEATS = [f\"z{w}\" for w in WINS]\n",
    "PROTOS = [(0.5, 5.0), (1.0, 1.0), (5.0, 0.5)]\n",
    "\n",
    "# Optimized theta parameters from the final model run\n",
    "THETA = np.array([\n",
    "    1.3507, 1.073, -1.226, 2.5141, 2.9946, -0.4083, -0.1082, -0.6809,\n",
    "    0.3465, -0.6804, -2.9974, -2.9991, -1.2658, -0.368, 0.7567, -1.9627,\n",
    "    -1.9124, 2.9983, 0.5704, 0.0, 0.8669, 1.2546, 5.0\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d35454",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c2137345",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Converts a vector of scores into a probability distribution.\"\"\"\n",
    "    ex = np.exp(x - x.max())\n",
    "    return ex / ex.sum()\n",
    "\n",
    "def allocate_sequential(raw: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Strict left-to-right 'drain' allocator.\"\"\"\n",
    "    n = len(raw)\n",
    "    floor = n * MIN_W\n",
    "    rem_budget, rem_raw = 1 - floor, raw.sum()\n",
    "    w = np.empty_like(raw)\n",
    "    for i, x in enumerate(raw):\n",
    "        share = 0 if rem_raw == 0 else (x / rem_raw) * rem_budget\n",
    "        w[i] = MIN_W + share\n",
    "        rem_budget -= share\n",
    "        rem_raw -= x\n",
    "    return w / w.sum()\n",
    "\n",
    "def beta_mix_pdf(n: int, mix: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Generates a smooth baseline curve from a mixture of Beta distributions.\"\"\"\n",
    "    t = np.linspace(0.5 / n, 1 - 0.5 / n, n)\n",
    "    return (mix[0] * beta.pdf(t, *PROTOS[0]) +\n",
    "            mix[1] * beta.pdf(t, *PROTOS[1]) +\n",
    "            mix[2] * beta.pdf(t, *PROTOS[2])) / n\n",
    "\n",
    "def zscore(s: pd.Series, win: int) -> pd.Series:\n",
    "    \"\"\"Calculates the rolling z-score for a given series and window.\"\"\"\n",
    "    m = s.rolling(win, win // 2).mean()\n",
    "    sd = s.rolling(win, win // 2).std()\n",
    "    return ((s - m) / sd).fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77f308b",
   "metadata": {},
   "source": [
    "## Main DCA Strategy Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "23cad4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Calculates features on the full historical data ONCE and returns the\n",
    "    relevant slice. This robustly handles calls from different boilerplate\n",
    "    functions and avoids boundary errors that cause leakage.\n",
    "    \"\"\"\n",
    "    global _FULL_FEATURES\n",
    "\n",
    "    # Only compute the full feature set if it hasn't been done yet.\n",
    "    if _FULL_FEATURES is None:\n",
    "        try:\n",
    "            # Assumes 'btc_data.csv' is in the same directory.\n",
    "            full_price_df = pd.read_csv(\"data/btc_data.csv\", index_col=0, parse_dates=True)\n",
    "        except FileNotFoundError:\n",
    "            raise FileNotFoundError(\"data/btc_data.csv not found. Please ensure it's in the correct directory.\")\n",
    "        \n",
    "        # Select only the PriceUSD column before doing anything else.\n",
    "        full_price_df = full_price_df[['PriceUSD']]\n",
    "        \n",
    "        # We need history from before the backtest start date for rolling windows.\n",
    "        full_price_df = full_price_df.loc[\"2010-07-18\":]\n",
    "        # full_price_df = full_price_df.loc[\"2010-07-18\":] \n",
    "\n",
    "        log_prices = np.log(full_price_df['PriceUSD'])\n",
    "        \n",
    "        z_all = pd.DataFrame({f\"z{w}\": zscore(log_prices, w).clip(-4, 4) for w in WINS}, index=log_prices.index)\n",
    "        \n",
    "        # The strategy uses lagged features to avoid look-ahead bias.\n",
    "        z_lag = z_all.shift(1).fillna(0)\n",
    "        \n",
    "        _FULL_FEATURES = full_price_df.join(z_lag)\n",
    "\n",
    "    # Return the portion of the pre-computed features that matches the input index.\n",
    "    return _FULL_FEATURES.reindex(df.index).fillna(0)\n",
    "\n",
    "\n",
    "def compute_weights(df_window: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Given a slice of data, computes portfolio weights that sum to 1.\n",
    "    This function first calls construct_features to ensure the necessary\n",
    "    feature columns are present.\n",
    "    \"\"\"\n",
    "    if df_window.empty:\n",
    "        return pd.Series(dtype=float)\n",
    "\n",
    "    feat_slice = construct_features(df_window)\n",
    "\n",
    "    alpha, beta_v = THETA[:18].reshape(3, 6), THETA[18:]\n",
    "    \n",
    "    # Use features from the first day to set the annual strategy\n",
    "    first_day_feats = feat_slice[FEATS].iloc[0].values\n",
    "    mix = softmax(alpha @ np.r_[1, first_day_feats])\n",
    "    \n",
    "    # Calculate the components of the allocation formula\n",
    "    n_days = len(feat_slice)\n",
    "    base_alloc = beta_mix_pdf(n_days, mix)\n",
    "    dynamic_signal = np.exp(-(feat_slice[FEATS].values @ beta_v))\n",
    "    \n",
    "    # Combine signals and compute final weights\n",
    "    raw_weights = base_alloc * dynamic_signal\n",
    "    final_weights = allocate_sequential(raw_weights)\n",
    "    \n",
    "    return pd.Series(final_weights, index=feat_slice.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3fb0565",
   "metadata": {},
   "source": [
    "# Run DCA Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8401810f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _make_window_label(window_start: pd.Timestamp, window_end: pd.Timestamp) -> str:\n",
    "    \"\"\"\n",
    "    Format \"YYYY-MM-DD → YYYY-MM-DD\" for a rolling window.\n",
    "    \"\"\"\n",
    "    start_str = pd.to_datetime(window_start).strftime(\"%Y-%m-%d\")\n",
    "    end_str   = pd.to_datetime(window_end).strftime(\"%Y-%m-%d\")\n",
    "    return f\"{start_str} → {end_str}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "dd9f5c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cycle_spd(\n",
    "    dataframe: pd.DataFrame,\n",
    "    strategy_function\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Compute sats‐per‐dollar (SPD) stats over rolling windows.\n",
    "\n",
    "    - Uses full‐history features (no look‐ahead).\n",
    "    - Window length = INVESTMENT_WINDOW months.\n",
    "    - Step every PURCHASE_FREQ.\n",
    "    - Returns a DataFrame indexed by window label, with:\n",
    "        min_sats_per_dollar, max_sats_per_dollar,\n",
    "        uniform_sats_per_dollar, dynamic_sats_per_dollar,\n",
    "        uniform_percentile, dynamic_percentile, excess_percentile.\n",
    "    \"\"\"\n",
    "    # 1) Precompute full-history features & restrict to backtest\n",
    "    full_feat = construct_features(dataframe).loc[BACKTEST_START:BACKTEST_END]\n",
    "\n",
    "    # 2) Window parameters\n",
    "    window_offset  = pd.DateOffset(months=INVESTMENT_WINDOW)\n",
    "    step_freq      = PURCHASE_FREQ_TO_OFFSET[PURCHASE_FREQ]\n",
    "\n",
    "    results = []\n",
    "    for window_start in pd.date_range(\n",
    "        start=pd.to_datetime(BACKTEST_START),\n",
    "        end=pd.to_datetime(BACKTEST_END) - window_offset,\n",
    "        freq=step_freq\n",
    "    ):\n",
    "        window_end  = window_start + window_offset\n",
    "        feat_slice  = full_feat.loc[window_start:window_end]\n",
    "        price_slice = dataframe[\"PriceUSD\"].loc[window_start:window_end]\n",
    "\n",
    "        if price_slice.empty:\n",
    "            continue\n",
    "\n",
    "        label       = _make_window_label(window_start, window_end)\n",
    "        inv_price   = (1.0 / price_slice) * 1e8  # sats per dollar\n",
    "\n",
    "        # Compute weights on this slice\n",
    "        weight_slice = strategy_function(feat_slice)\n",
    "\n",
    "        # Uniform vs. dynamic SPD\n",
    "        uniform_spd = inv_price.mean()\n",
    "        dynamic_spd = (weight_slice * inv_price).sum()\n",
    "\n",
    "        # Min/max for percentile scaling\n",
    "        min_spd = inv_price.min()   # low price → high SPD\n",
    "        max_spd = inv_price.max()   # high price → low SPD\n",
    "        span    = max_spd - min_spd\n",
    "\n",
    "        uniform_pct = (uniform_spd - min_spd) / span * 100\n",
    "        dynamic_pct = (dynamic_spd - min_spd) / span * 100\n",
    "\n",
    "        results.append({\n",
    "            \"window\":                   label,\n",
    "            \"min_sats_per_dollar\":      min_spd,\n",
    "            \"max_sats_per_dollar\":      max_spd,\n",
    "            \"uniform_sats_per_dollar\":  uniform_spd,\n",
    "            \"dynamic_sats_per_dollar\":  dynamic_spd,\n",
    "            \"uniform_percentile\":       uniform_pct,\n",
    "            \"dynamic_percentile\":       dynamic_pct,\n",
    "            \"excess_percentile\":        dynamic_pct - uniform_pct,\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(results).set_index(\"window\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6db1a64",
   "metadata": {},
   "source": [
    "# Other Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b379ff16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_weight(\n",
    "    dataframe: pd.DataFrame,\n",
    "    strategy_function\n",
    ") -> pd.DataFrame:\n",
    "    # 1) Precompute full-history features & restrict to backtest\n",
    "    full_feat = construct_features(dataframe).loc[BACKTEST_START:BACKTEST_END]\n",
    "\n",
    "    # 2) Window parameters\n",
    "    window_offset  = pd.DateOffset(months=INVESTMENT_WINDOW)\n",
    "    step_freq = PURCHASE_FREQ_TO_OFFSET[PURCHASE_FREQ]\n",
    "\n",
    "    all_weights = []\n",
    "\n",
    "    for window_start in pd.date_range(\n",
    "        start=pd.to_datetime(BACKTEST_START),\n",
    "        end=pd.to_datetime(BACKTEST_END) - window_offset,\n",
    "        freq=pd.DateOffset(months=INVESTMENT_WINDOW)\n",
    "    ):\n",
    "        window_end  = window_start + window_offset\n",
    "        feat_slice  = full_feat.loc[window_start:window_end]\n",
    "\n",
    "        # Compute weights on this slice\n",
    "        weight_slice = strategy_function(feat_slice)\n",
    "\n",
    "        all_weights.append(weight_slice)\n",
    "\n",
    "    final_series = pd.concat(all_weights, ignore_index=False)\n",
    "\n",
    "    final_series = final_series.reset_index()\n",
    "    final_series.columns = [\"date\", \"weight\"]\n",
    "\n",
    "    return final_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3c65153b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_weight_price(btc_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Combine extract_weight output with btc_df on date (btc_df index).\n",
    "    Output columns: [\"date\", \"weight\", \"PriceUSD\"]\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. Get weights (date, weight)\n",
    "    df_weight = extract_weight(btc_df, compute_weights)\n",
    "\n",
    "    # Ensure datetime\n",
    "    df_weight[\"date\"] = pd.to_datetime(df_weight[\"date\"])\n",
    "\n",
    "    # 2. Prepare btc_df (date is in index)\n",
    "    df_price = btc_df.copy()\n",
    "    df_price.index = pd.to_datetime(df_price.index)\n",
    "\n",
    "    # Move index to column called \"date\"\n",
    "    df_price = df_price.reset_index().rename(columns={\"time\": \"date\"})\n",
    "\n",
    "    # Keep only what we need\n",
    "    df_price = df_price[[\"date\", \"PriceUSD\"]]\n",
    "\n",
    "    # 3. Merge on date\n",
    "    df_combo = pd.merge(\n",
    "        df_weight,\n",
    "        df_price,\n",
    "        on=\"date\",\n",
    "        how=\"inner\"\n",
    "    )\n",
    "\n",
    "    # 4. Sort and reset index\n",
    "    df_combo = df_combo.sort_values(\"date\")\n",
    "    df_combo = df_combo.drop_duplicates(subset=\"date\", keep=\"last\")\n",
    "    df_combo = df_combo.reset_index(drop=True)\n",
    "\n",
    "    df_combo = df_combo.set_index(\"date\")\n",
    "\n",
    "    return df_combo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c6d833ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_spd_percentile(\n",
    "    file_path: str = \"data/weight_price_ma20.csv\",\n",
    "    output_path: str = \"data/weight_price_ma20_spd_pct.csv\"\n",
    "):\n",
    "    # Load data\n",
    "    df = pd.read_csv(file_path)\n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "    df = df.sort_values(\"date\")\n",
    "\n",
    "    # Define window year (June 1 – May 31)\n",
    "    year = df[\"date\"].dt.year\n",
    "    month = df[\"date\"].dt.month\n",
    "\n",
    "    # June–December => current year, January–May => previous year\n",
    "    df[\"window_year\"] = np.where(month >= 6, year, year - 1)\n",
    "    \n",
    "    # spd = 1 / (BTC/USD) * 100,000,000 \n",
    "    df[\"spd\"] = (1 / df[\"PriceUSD\"]) * 100_000_000\n",
    "\n",
    "    # Get min / max price in each window year\n",
    "    grp = df.groupby(\"window_year\")[\"spd\"]\n",
    "    worst_spd = grp.transform(\"min\")\n",
    "    best_spd = grp.transform(\"max\")\n",
    "\n",
    "    # spd_pct = (your SPD - worst SPD) / (best SPD - worst SPD) * 100\n",
    "    df[\"spd_percentile\"] = (df[\"spd\"] - worst_spd) / (best_spd - worst_spd) * 100\n",
    "\n",
    "    # Drop rows where price_percentile is NaN\n",
    "    df = df.dropna(subset=[\"spd_percentile\"])\n",
    "\n",
    "    # Round to integer\n",
    "    df[\"spd_percentile\"] = df[\"spd_percentile\"].round().astype(int)\n",
    "\n",
    "    # Save file\n",
    "    df.to_csv(output_path, index=False)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fee2ca0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_forward_returns(\n",
    "    file_path: str = \"data/weight_price_ma20_spd_pct.csv\",\n",
    "    output_path: str = \"data/weight_price_ma20_spd_pct_return.csv\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Add forward returns (30d, 60d, 365d) based on PriceUSD.\n",
    "    Return is calculated as: (future_price / current_price) - 1\n",
    "    \"\"\"\n",
    "\n",
    "    # Load data\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Ensure datetime and sorted\n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "    df = df.sort_values(\"date\")\n",
    "\n",
    "    # Make sure price is numeric\n",
    "    df[\"PriceUSD\"] = pd.to_numeric(df[\"PriceUSD\"], errors=\"coerce\")\n",
    "\n",
    "    # Add forward returns\n",
    "    df[\"30d_return\"]  = (df[\"PriceUSD\"].shift(-30)  / df[\"PriceUSD\"]) - 1\n",
    "    df[\"60d_return\"]  = (df[\"PriceUSD\"].shift(-60)  / df[\"PriceUSD\"]) - 1\n",
    "    df[\"365d_return\"] = (df[\"PriceUSD\"].shift(-365) / df[\"PriceUSD\"]) - 1\n",
    "\n",
    "    # Drop rows where any of the return columns is NaN\n",
    "    df = df.dropna(subset=[\"30d_return\", \"60d_return\", \"365d_return\"])\n",
    "\n",
    "    df.to_csv(output_path, index=False)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12153ae",
   "metadata": {},
   "source": [
    "# Run main workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122e7205",
   "metadata": {},
   "source": [
    "## Load BTC Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2b0fe31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "btc_df = load_data()\n",
    "validate_price_data(btc_df)\n",
    "btc_df = btc_df.loc[BACKTEST_START:BACKTEST_END]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f57cc5a",
   "metadata": {},
   "source": [
    "## Load weight and price through each windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "97bf8d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_w_p = combine_weight_price(btc_df)\n",
    "df_w_p.to_csv(\"data/weight_price.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2618e491",
   "metadata": {},
   "source": [
    "## Load MA20 through each windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c9315007",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_w_p[\"MA20\"] = df_w_p[\"PriceUSD\"].rolling(window=20).mean()\n",
    "df_w_p.to_csv(\"data/weight_price_ma20.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc447a5",
   "metadata": {},
   "source": [
    "# Load percentile through each windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "296e34aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dr/_j6dcxqs3zn8h1179k47j1s80000gn/T/ipykernel_34153/1475057675.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"spd_percentile\"] = df[\"spd_percentile\"].round().astype(int)\n"
     ]
    }
   ],
   "source": [
    "df_w_p_spd_pct = compute_spd_percentile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cde56f2",
   "metadata": {},
   "source": [
    "## Load Return through each windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "936e2590",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_w_p_spd_pct_r = add_forward_returns()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b6c53c",
   "metadata": {},
   "source": [
    "## Load Rolling-window SPD backtested Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1e26c73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spd = compute_cycle_spd(btc_df, compute_weights)\n",
    "df_spd.to_csv(\"data/backtested_btc_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3c7f107d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>min_sats_per_dollar</th>\n",
       "      <th>max_sats_per_dollar</th>\n",
       "      <th>uniform_sats_per_dollar</th>\n",
       "      <th>dynamic_sats_per_dollar</th>\n",
       "      <th>uniform_percentile</th>\n",
       "      <th>dynamic_percentile</th>\n",
       "      <th>excess_percentile</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>window</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-05-28 → 2025-05-28</th>\n",
       "      <td>897.045908</td>\n",
       "      <td>1857.39123</td>\n",
       "      <td>1300.336244</td>\n",
       "      <td>1759.101721</td>\n",
       "      <td>41.994304</td>\n",
       "      <td>89.765191</td>\n",
       "      <td>47.770887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-29 → 2025-05-29</th>\n",
       "      <td>897.045908</td>\n",
       "      <td>1857.39123</td>\n",
       "      <td>1298.922494</td>\n",
       "      <td>1758.942928</td>\n",
       "      <td>41.847091</td>\n",
       "      <td>89.748656</td>\n",
       "      <td>47.901565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-30 → 2025-05-30</th>\n",
       "      <td>897.045908</td>\n",
       "      <td>1857.39123</td>\n",
       "      <td>1297.507403</td>\n",
       "      <td>1758.803621</td>\n",
       "      <td>41.699739</td>\n",
       "      <td>89.734150</td>\n",
       "      <td>48.034411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-31 → 2025-05-31</th>\n",
       "      <td>897.045908</td>\n",
       "      <td>1857.39123</td>\n",
       "      <td>1296.120833</td>\n",
       "      <td>1758.766249</td>\n",
       "      <td>41.555357</td>\n",
       "      <td>89.730259</td>\n",
       "      <td>48.174902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-06-01 → 2025-06-01</th>\n",
       "      <td>897.045908</td>\n",
       "      <td>1857.39123</td>\n",
       "      <td>1294.649401</td>\n",
       "      <td>1758.600634</td>\n",
       "      <td>41.402138</td>\n",
       "      <td>89.713013</td>\n",
       "      <td>48.310875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         min_sats_per_dollar  max_sats_per_dollar  \\\n",
       "window                                                              \n",
       "2024-05-28 → 2025-05-28           897.045908           1857.39123   \n",
       "2024-05-29 → 2025-05-29           897.045908           1857.39123   \n",
       "2024-05-30 → 2025-05-30           897.045908           1857.39123   \n",
       "2024-05-31 → 2025-05-31           897.045908           1857.39123   \n",
       "2024-06-01 → 2025-06-01           897.045908           1857.39123   \n",
       "\n",
       "                         uniform_sats_per_dollar  dynamic_sats_per_dollar  \\\n",
       "window                                                                      \n",
       "2024-05-28 → 2025-05-28              1300.336244              1759.101721   \n",
       "2024-05-29 → 2025-05-29              1298.922494              1758.942928   \n",
       "2024-05-30 → 2025-05-30              1297.507403              1758.803621   \n",
       "2024-05-31 → 2025-05-31              1296.120833              1758.766249   \n",
       "2024-06-01 → 2025-06-01              1294.649401              1758.600634   \n",
       "\n",
       "                         uniform_percentile  dynamic_percentile  \\\n",
       "window                                                            \n",
       "2024-05-28 → 2025-05-28           41.994304           89.765191   \n",
       "2024-05-29 → 2025-05-29           41.847091           89.748656   \n",
       "2024-05-30 → 2025-05-30           41.699739           89.734150   \n",
       "2024-05-31 → 2025-05-31           41.555357           89.730259   \n",
       "2024-06-01 → 2025-06-01           41.402138           89.713013   \n",
       "\n",
       "                         excess_percentile  \n",
       "window                                      \n",
       "2024-05-28 → 2025-05-28          47.770887  \n",
       "2024-05-29 → 2025-05-29          47.901565  \n",
       "2024-05-30 → 2025-05-30          48.034411  \n",
       "2024-05-31 → 2025-05-31          48.174902  \n",
       "2024-06-01 → 2025-06-01          48.310875  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_spd.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a56335",
   "metadata": {},
   "source": [
    "## Load Allocation Animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5e3ff3e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-23 21:16:35 INFO     Animation.save using <class 'matplotlib.animation.PillowWriter'>\n"
     ]
    }
   ],
   "source": [
    "def zscore(s: pd.Series, win: int) -> pd.Series:\n",
    "    m  = s.rolling(win, win // 2).mean()\n",
    "    sd = s.rolling(win, win // 2).std()\n",
    "    return ((s - m) / sd).fillna(0)\n",
    "\n",
    "\n",
    "def fetch_btc() -> pd.Series:\n",
    "    url, cache = (\"https://raw.githubusercontent.com/coinmetrics/data/\"\n",
    "                  \"master/csv/btc.csv\", Path(\"btc.csv\"))\n",
    "    try:\n",
    "        txt = requests.get(url, timeout=15).text\n",
    "        cache.write_text(txt)\n",
    "    except Exception:\n",
    "        txt = cache.read_text()\n",
    "    df = pd.read_csv(io.StringIO(txt), usecols=[\"time\", \"PriceUSD\"])\n",
    "    df[\"date\"] = pd.to_datetime(df[\"time\"]).dt.normalize()\n",
    "    df.set_index(\"date\", inplace=True)\n",
    "    return df[\"PriceUSD\"].loc[\"2010-07-18\":].astype(float)\n",
    "\n",
    "price_full = fetch_btc()\n",
    "log_full   = np.log(price_full)\n",
    "price      = price_full.loc[BACKTEST_START:BACKTEST_END]\n",
    "\n",
    "z_all = pd.DataFrame({f\"z{w}\": zscore(log_full, w).clip(-4, 4) for w in WINS})\n",
    "z_lag = z_all.shift(1).fillna(0)\n",
    "\n",
    "FEATS = z_lag.columns.tolist()\n",
    "\n",
    "BACKTEST_START = pd.Timestamp(\"2011-06-01\")\n",
    "BACKTEST_END   = pd.Timestamp(\"2025-06-01\")\n",
    "\n",
    "WINDOW_STARTS = pd.date_range(\n",
    "    BACKTEST_START,\n",
    "    BACKTEST_END - pd.Timedelta(364, \"D\"),\n",
    "    freq=\"D\"\n",
    ")\n",
    "WINDOW_N = len(WINDOW_STARTS)\n",
    "\n",
    "def uniform_spd_pct(idx: pd.DatetimeIndex) -> float:\n",
    "    w  = np.full(len(idx), 1 / len(idx))\n",
    "    btc = (w / price.loc[idx].values).sum()\n",
    "    worst, best = 1 / price.loc[idx].max(), 1 / price.loc[idx].min()\n",
    "    return 100 * (btc - worst) / (best - worst)\n",
    "\n",
    "UNIFORM_PCT = np.array([\n",
    "    uniform_spd_pct(price.loc[s : s + pd.Timedelta(364, \"D\")].index)\n",
    "    for s in WINDOW_STARTS\n",
    "])\n",
    "\n",
    "MONTHLY_MASK = np.isin(\n",
    "    WINDOW_STARTS,\n",
    "    pd.date_range(BACKTEST_START,\n",
    "                  BACKTEST_END - pd.Timedelta(364, \"D\"),\n",
    "                  freq=\"MS\")\n",
    ") \n",
    "\n",
    "# ── parameters & window list ────────────────────────────────────────\n",
    "α = THETA[:18].reshape(3, 6)\n",
    "β = THETA[18:]\n",
    "\n",
    "# keep only one window out of every three monthly starts  →  ~quarterly\n",
    "WINDOW_QUARTERLY = WINDOW_STARTS[MONTHLY_MASK][::3]\n",
    "\n",
    "def beta_curve(n=365, mix=(1/3, 1/3, 1/3)):\n",
    "    x = np.linspace(0.5/n, 1 - 0.5/n, n)\n",
    "    y = (mix[0] * beta.pdf(x, *PROTOS[0]) +\n",
    "         mix[1] * beta.pdf(x, *PROTOS[1]) +\n",
    "         mix[2] * beta.pdf(x, *PROTOS[2]))\n",
    "    return y / y.sum()\n",
    "\n",
    "# ── figure skeleton ────────────────────────────────────────────────\n",
    "fig, (ax_p, ax_w) = plt.subplots(\n",
    "    2, 1, figsize=(8, 5), dpi=150,\n",
    "    gridspec_kw={'height_ratios': [1, 1]},\n",
    "    constrained_layout=True\n",
    ")\n",
    "\n",
    "# ── per-frame draw routine ─────────────────────────────────────────\n",
    "def update_frame(k):\n",
    "    start = WINDOW_QUARTERLY[k]\n",
    "    end   = start + pd.Timedelta(364, 'D')\n",
    "    idx   = price_full.loc[start:end].index\n",
    "    if len(idx) < 365:\n",
    "        return\n",
    "\n",
    "    # ----- weights -------------------------------------------------------\n",
    "    z0   = z_lag.loc[start, FEATS].values\n",
    "    mix  = softmax(α @ np.r_[1, z0])\n",
    "    base = beta_curve(365, mix)\n",
    "    mod  = np.exp(-(z_lag.loc[idx, FEATS].values @ β))\n",
    "    w    = allocate_sequential(base * mod)\n",
    "\n",
    "    # ----- clear axes ----------------------------------------------------\n",
    "    ax_p.cla()\n",
    "    ax_w.cla()\n",
    "\n",
    "    # ----- price panel ---------------------------------------------------\n",
    "    ax_p.plot(idx, price_full.loc[idx], lw=1.4, color='black')\n",
    "    ax_p.set_ylabel(\"BTC price [USD]\", fontsize=9)\n",
    "    ax_p.set_xlim(idx.min(), idx.max())\n",
    "    ax_p.grid(alpha=0.25)\n",
    "\n",
    "    # ----- allocation panel (log-scale) ---------------------------------\n",
    "    xnum = mdates.date2num(idx)\n",
    "    ax_w.plot(idx, base, lw=1.2, color='lightgray', alpha=0.5)\n",
    "    ax_w.vlines(xnum, base, w, color='orange', lw=2.2, alpha=0.5)\n",
    "    ax_w.scatter(idx, w, color='orange', s=20, zorder=3, alpha=1)\n",
    "    ax_w.set_yscale('log')\n",
    "    ax_w.set_ylabel(\"Weight (log)\", fontsize=9)\n",
    "    ax_w.set_xlim(idx.min(), idx.max())\n",
    "    ax_w.set_ylim(MIN_W * 0.8, w.max() * 1.4)\n",
    "    ax_w.grid(alpha=0.25)\n",
    "\n",
    "    # ----- shared X-axis formatting -------------------------------------\n",
    "    locator   = mdates.AutoDateLocator()\n",
    "    formatter = mdates.DateFormatter(\"%b %Y\")\n",
    "    for ax in (ax_p, ax_w):\n",
    "        ax.xaxis.set_major_locator(locator)\n",
    "        ax.xaxis.set_major_formatter(formatter)\n",
    "        ax.tick_params(axis='x', rotation=45, labelsize=7)\n",
    "        ax.tick_params(axis='y', labelsize=7)\n",
    "\n",
    "# ── build & save GIF (1 fps) ────────────────────────────────────────\n",
    "anim = FuncAnimation(\n",
    "    fig,\n",
    "    update_frame,\n",
    "    frames=len(WINDOW_QUARTERLY),\n",
    "    interval=1200,    # 500 ms per frame\n",
    "    blit=False\n",
    ")\n",
    "\n",
    "anim.save(\"data/allocation_animation_quarterly.gif\", writer=PillowWriter(fps=1))\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8259ed26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
